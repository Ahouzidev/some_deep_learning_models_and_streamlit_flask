{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIABETIC RETINOPATHY CLASSIFICATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "# ========== DATA AUGMENTATION ==========\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    layers.RandomContrast(0.2),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# ========== LOAD DATA ==========\n",
    "print(\"Loading dataset...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/dataset\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/dataset\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\nClasses detected: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Split validation and test sets\n",
    "val_batches = tf.data.experimental.cardinality(val_test_ds)\n",
    "val_size = val_batches // 2\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Training batches: {tf.data.experimental.cardinality(train_ds)}\")\n",
    "print(f\"  Validation batches: {tf.data.experimental.cardinality(val_ds)}\")\n",
    "print(f\"  Test batches: {tf.data.experimental.cardinality(test_ds)}\")\n",
    "\n",
    "# Optimize performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# ========== CALCULATE CLASS WEIGHTS ==========\n",
    "print(\"\\nCalculating class weights for imbalanced data...\")\n",
    "labels = []\n",
    "for _, batch_labels in train_ds:\n",
    "    labels.extend(batch_labels.numpy())\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = labels.count(i)\n",
    "    print(f\"  {name}: {count} samples (weight: {class_weights[i]:.2f})\")\n",
    "\n",
    "# ========== BUILD MODEL ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUILDING MODEL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "base_model = EfficientNetB0(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# ========== CALLBACKS ==========\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=25,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='max'\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_diabetic_retinopathy_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# ========== TRAINING ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ========== EVALUATION ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"‚úì Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"‚úì Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "    y_pred_proba.extend(predictions)\n",
    "\n",
    "# ========== DETAILED METRICS ==========\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED PER-CLASS METRICS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(f\"{'Class':<20} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "print(\"-\" * 66)\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{name:<20} {precision[i]:>7.3f}      {recall[i]:>7.3f}      {f1[i]:>7.3f}      {support[i]:>5}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 66)\n",
    "print(f\"{'Accuracy':<20} {test_accuracy:>7.3f}\")\n",
    "print(f\"{'Macro Avg F1':<20} {np.mean(f1):>7.3f}\")\n",
    "print(f\"{'Weighted Avg F1':<20} {np.average(f1, weights=support):>7.3f}\")\n",
    "\n",
    "# ========== CONFUSION MATRIX ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Number of Predictions'},\n",
    "            annot_kws={'size': 14, 'weight': 'bold'})\n",
    "plt.title('Confusion Matrix - Diabetic Retinopathy Classification', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== TRAINING HISTORY ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING HISTORY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "best_epoch = np.argmax(val_acc) + 1\n",
    "best_val_acc = max(val_acc)\n",
    "\n",
    "print(f\"Training completed in {len(acc)} epochs\")\n",
    "print(f\"Best validation accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"Final training accuracy: {acc[-1]*100:.2f}%\")\n",
    "print(f\"Final validation accuracy: {val_acc[-1]*100:.2f}%\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 0].plot(acc, 'b-', linewidth=2, label='Training Accuracy')\n",
    "axes[0, 0].plot(val_acc, 'r-', linewidth=2, label='Validation Accuracy')\n",
    "axes[0, 0].axvline(x=best_epoch-1, color='green', linestyle='--', \n",
    "                   linewidth=2, alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "axes[0, 0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].legend(loc='lower right', fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 1].plot(loss, 'b-', linewidth=2, label='Training Loss')\n",
    "axes[0, 1].plot(val_loss, 'r-', linewidth=2, label='Validation Loss')\n",
    "axes[0, 1].axvline(x=best_epoch-1, color='green', linestyle='--', \n",
    "                   linewidth=2, alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "axes[0, 1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 1].legend(loc='upper right', fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting analysis\n",
    "gap = np.array(acc) - np.array(val_acc)\n",
    "axes[1, 0].plot(gap, 'purple', linewidth=2)\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1, 0].fill_between(range(len(gap)), gap, 0, alpha=0.3, color='purple')\n",
    "axes[1, 0].set_title('Overfitting Analysis (Train-Val Gap)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Accuracy Difference', fontsize=12)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy = [cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0 \n",
    "                  for i in range(len(class_names))]\n",
    "colors = ['green' if acc > 0.7 else 'orange' if acc > 0.5 else 'red' \n",
    "          for acc in class_accuracy]\n",
    "axes[1, 1].bar(range(len(class_names)), class_accuracy, color=colors, alpha=0.7)\n",
    "axes[1, 1].set_title('Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Class', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1, 1].set_xticks(range(len(class_names)))\n",
    "axes[1, 1].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    axes[1, 1].text(i, acc + 0.02, f'{acc*100:.1f}%', \n",
    "                    ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== SAMPLE PREDICTIONS ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS VISUALIZATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "sample_idx = 0\n",
    "for images, labels in test_ds.take(3):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    for i in range(min(5, len(images))):\n",
    "        if sample_idx >= 15:\n",
    "            break\n",
    "        \n",
    "        axes[sample_idx].imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        pred_class = np.argmax(predictions[i])\n",
    "        true_class = labels[i].numpy()\n",
    "        confidence = predictions[i][pred_class] * 100\n",
    "        \n",
    "        # Get top 2 predictions\n",
    "        top2_idx = np.argsort(predictions[i])[-2:][::-1]\n",
    "        \n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        \n",
    "        title = f\"True: {class_names[true_class]}\\n\"\n",
    "        title += f\"Predicted: {class_names[pred_class]}\\n\"\n",
    "        title += f\"Confidence: {confidence:.1f}%\"\n",
    "        \n",
    "        if pred_class != true_class:\n",
    "            title += f\"\\n(2nd: {class_names[top2_idx[1]]}, {predictions[i][top2_idx[1]]*100:.1f}%)\"\n",
    "        \n",
    "        axes[sample_idx].set_title(title, color=color, fontsize=10, fontweight='bold')\n",
    "        axes[sample_idx].axis('off')\n",
    "        sample_idx += 1\n",
    "    \n",
    "    if sample_idx >= 15:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ========== FINAL SUMMARY ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"üìä Best Validation Accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"üìà Macro F1-Score: {np.mean(f1)*100:.2f}%\")\n",
    "print(f\"‚öñÔ∏è  Weighted F1-Score: {np.average(f1, weights=support)*100:.2f}%\")\n",
    "print(f\"\\nüèÜ Best Performing Class: {class_names[np.argmax(recall)]} ({recall[np.argmax(recall)]*100:.1f}% recall)\")\n",
    "print(f\"‚ö†Ô∏è  Weakest Class: {class_names[np.argmin(recall)]} ({recall[np.argmin(recall)]*100:.1f}% recall)\")\n",
    "print(f\"\\nüìÅ Model saved and ready for deployment!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNdS1T0Vn7l59Zgercke0of",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
